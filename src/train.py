import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib
import mlflow
import yaml
import os


def load_params():
    params = {}
    try:
        with open("params.yaml", "r") as f:
            params = yaml.safe_load(f)
    except FileNotFoundError:
        print("ê²½ê³ : params.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        params = {
            "train": {
                "alpha": 0.1,
                "max_iter": 1000,
                "random_state": 42,
                "test_size": 0.2,
                "model_type": "ridge",
            }
        }
    return params.get("train", {})


def get_model(model_type, alpha, max_iter, random_state):
    """ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if model_type.lower() == "linear":
        return LinearRegression()
    elif model_type.lower() == "ridge":
        return Ridge(alpha=alpha, max_iter=max_iter, random_state=random_state)
    elif model_type.lower() == "lasso":
        return Lasso(alpha=alpha, max_iter=max_iter, random_state=random_state)
    else:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ íƒ€ì…: {model_type}. LinearRegressionì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return LinearRegression()


if __name__ == "__main__":
    params = load_params()
    alpha = params.get("alpha", 0.1)
    max_iter = params.get("max_iter", 1000)
    random_state = params.get("random_state", 42)
    test_size = params.get("test_size", 0.2)
    model_type = params.get("model_type", "ridge")

    print(f"ğŸ“ˆ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    print(f"   - ëª¨ë¸ íƒ€ì…: {model_type}")
    print(f"   - Alpha: {alpha}")
    print(f"   - Max Iterations: {max_iter}")
    print(f"   - Random State: {random_state}")
    print(f"   - Test Size: {test_size}")

    with mlflow.start_run(run_name=f"{model_type.capitalize()}_Training_alpha_{alpha}"):
        # íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_param("alpha", alpha)
        mlflow.log_param("max_iter", max_iter)
        mlflow.log_param("random_state", random_state)
        mlflow.log_param("test_size", test_size)
        mlflow.log_param("model_type", model_type)

        # ë°ì´í„° ë¡œë“œ
        df = pd.read_csv("data/raw_data.csv")
        print(f"ğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰, {len(df.columns)} ì—´")

        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        feature_columns = [col for col in df.columns if col.startswith("feature")]
        X = df[feature_columns]
        y = df["target"]

        print(f"ğŸ” ì‚¬ìš©ëœ íŠ¹ì„±: {feature_columns}")
        print(f"ğŸ“ˆ íŠ¹ì„± ê°œìˆ˜: {len(feature_columns)}")

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )

        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        print(f"ğŸ“Š í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]} ìƒ˜í”Œ")
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]} ìƒ˜í”Œ")

        # ëª¨ë¸ ìƒì„± ë° í›ˆë ¨
        model = get_model(model_type, alpha, max_iter, random_state)
        model.fit(X_train_scaled, y_train)

        # í›ˆë ¨ ì„±ëŠ¥ í‰ê°€
        train_score = model.score(X_train_scaled, y_train)
        test_score = model.score(X_test_scaled, y_test)

        print(f"âœ… í›ˆë ¨ RÂ² ì ìˆ˜: {train_score:.4f}")
        print(f"âœ… í…ŒìŠ¤íŠ¸ RÂ² ì ìˆ˜: {test_score:.4f}")

        # MLflowì— ë©”íŠ¸ë¦­ ë¡œê¹…
        mlflow.log_metric("train_r2_score", train_score)
        mlflow.log_metric("test_r2_score", test_score)

        # ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        model_dir = "model"
        os.makedirs(model_dir, exist_ok=True)

        model_path = os.path.join(model_dir, f"{model_type}_model.pkl")
        scaler_path = os.path.join(model_dir, "scaler.pkl")

        joblib.dump(model, model_path)
        joblib.dump(scaler, scaler_path)

        print(f"âœ… ëª¨ë¸ì´ {model_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ê°€ {scaler_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # MLflowì— ì•„í‹°íŒ©íŠ¸ ë¡œê¹…
        mlflow.log_artifact(model_path)
        mlflow.log_artifact(scaler_path)
        print("âœ… MLflow: ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ì•„í‹°íŒ©íŠ¸ê°€ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # íŠ¹ì„± ì¤‘ìš”ë„ (ê³„ìˆ˜) ë¡œê¹…
        if hasattr(model, "coef_"):
            feature_importance = dict(zip(feature_columns, model.coef_))
            print("ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ (ê³„ìˆ˜):")
            for feature, coef in feature_importance.items():
                print(f"   {feature}: {coef:.4f}")
                mlflow.log_param(f"coef_{feature}", coef)
